{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQsQXWJ-sgFC"
      },
      "source": [
        "# WordNet\n",
        "\n",
        "## Summary\n",
        "\n",
        "WordNet is a free and publically downloadable corpus of English words. This lexical database contains labeled and grouped sets of synsets -- which are cognitive synonyms linked together by lexical relationships. Essentially, it's grouped together by how similar the words are based on their meanings (semantics)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42HbmuZDshql",
        "outputId": "df0f077d-eeea-4c84-af9a-45320a893e22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtsII5xqsuhw",
        "outputId": "f1c4d823-f165-47e3-ad1f-fe2f3342af3d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrjrI3WsgFI",
        "outputId": "3526ffd3-23cb-4013-9cd3-8a5c1a813c96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('leg.n.01'),\n",
              " Synset('leg.n.02'),\n",
              " Synset('leg.n.03'),\n",
              " Synset('branch.n.03'),\n",
              " Synset('leg.n.05'),\n",
              " Synset('peg.n.04'),\n",
              " Synset('leg.n.07'),\n",
              " Synset('leg.n.08'),\n",
              " Synset('stage.n.06')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Output all synsets of `leg`\n",
        "wn.synsets('leg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJCTVHvxsgFM",
        "outputId": "98c839f7-094f-44ac-f28a-7b8d262df3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: n.n.06\n",
            "Definition: a section or portion of a journey or course\n",
            "Usage Examples: ['then we embarked on the second stage of our Caribbean cruise']\n",
            "Lemmas: [Lemma('stage.n.06.stage'), Lemma('stage.n.06.leg')]\n"
          ]
        }
      ],
      "source": [
        "# Using the synset `n.n.06`, we will output its definition, usage examples, and lemmas\n",
        "n = wn.synset('stage.n.06')\n",
        "print('Synset: n.n.06')\n",
        "print('Definition:', n.definition())\n",
        "print('Usage Examples:', n.examples())\n",
        "print('Lemmas:', n.lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnjLiQ3jsgFO",
        "outputId": "81aaf24f-1d15-44ad-df61-e73ce31f57e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('travel.n.01'),\n",
              " Synset('motion.n.06'),\n",
              " Synset('change.n.03'),\n",
              " Synset('action.n.01'),\n",
              " Synset('act.n.02'),\n",
              " Synset('event.n.01'),\n",
              " Synset('psychological_feature.n.01'),\n",
              " Synset('abstraction.n.06'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Traverse up the WordNet and print out all synsets\n",
        "list(n.closure(lambda x : x.hypernyms()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLX84-hVsgFP"
      },
      "source": [
        "The nouns are organized with more general concepts on top. For my example, notice how event appears above travel -- this is in relation to how \"event\" is significantly more broad than \"travel\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz8HrDUgsgFQ",
        "outputId": "8e9f86f4-0ed9-4f2b-e67f-b1bce0781348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypernyms: [Synset('travel.n.01')]\n",
            "Hyponyms: [Synset('fare-stage.n.01')]\n",
            "Meronyms: []\n",
            "Holonyms: [Synset('journey.n.01')]\n",
            "Antonyms: []\n"
          ]
        }
      ],
      "source": [
        "def test_nym(func, syn):\n",
        "    try:\n",
        "        return func(syn)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# Print all: hypernyms, hyponyms, meronyms, holonyms, antonym\n",
        "print('Hypernyms:', test_nym(lambda x : x.hypernyms(), n))\n",
        "print('Hyponyms:', test_nym(lambda x : x.hyponyms(), n))\n",
        "print('Meronyms:', test_nym(lambda x : x.part_meronyms(), n))\n",
        "print('Holonyms:', test_nym(lambda x : x.part_holonyms(), n))\n",
        "print('Antonyms:', test_nym(lambda x : x.antonyms(), n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwayZ39msgFS",
        "outputId": "b4b9bc87-8660-4222-c2c4-60b7dc23d4a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('jump.n.01'),\n",
              " Synset('leap.n.02'),\n",
              " Synset('jump.n.03'),\n",
              " Synset('startle.n.01'),\n",
              " Synset('jump.n.05'),\n",
              " Synset('jump.n.06'),\n",
              " Synset('jump.v.01'),\n",
              " Synset('startle.v.02'),\n",
              " Synset('jump.v.03'),\n",
              " Synset('jump.v.04'),\n",
              " Synset('leap_out.v.01'),\n",
              " Synset('jump.v.06'),\n",
              " Synset('rise.v.11'),\n",
              " Synset('jump.v.08'),\n",
              " Synset('derail.v.02'),\n",
              " Synset('chute.v.01'),\n",
              " Synset('jump.v.11'),\n",
              " Synset('jumpstart.v.01'),\n",
              " Synset('jump.v.13'),\n",
              " Synset('leap.v.02'),\n",
              " Synset('alternate.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "wn.synsets('jump')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpauH6SesgFT",
        "outputId": "174dccb7-f0ce-4085-ba72-b70a810c5c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: startle.v.02\n",
            "Definition: move or jump suddenly, as if in surprise or alarm\n",
            "Usage Examples: ['She startled when I walked into the room']\n",
            "Lemmas: [Lemma('startle.v.02.startle'), Lemma('startle.v.02.jump'), Lemma('startle.v.02.start')]\n"
          ]
        }
      ],
      "source": [
        "v = wn.synset('startle.v.02')\n",
        "print('Synset: startle.v.02')\n",
        "print('Definition:', v.definition())\n",
        "print('Usage Examples:', v.examples())\n",
        "print('Lemmas:', v.lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thCdH6MasgFV",
        "outputId": "3cb8207c-4365-4394-b565-6eea38885c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('move.v.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Traverse up the WordNet and print out all synsets\n",
        "list(v.closure(lambda x : x.hypernyms()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lybqvb1ysgFW"
      },
      "source": [
        "Similar to the nouns, the verbs are also organized into a similar hierarchy. The more broad verbs are classified above in the hierarchy the more specific verbs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGbO028DsgFX",
        "outputId": "c91575ad-b6a1-4f17-9500-c26b49d0b2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jump\n",
            "jump\n",
            "jump\n",
            "jumping\n"
          ]
        }
      ],
      "source": [
        "print(wn.morphy('jumped'))\n",
        "print(wn.morphy('jumps'))\n",
        "print(wn.morphy('jump'))\n",
        "\n",
        "# Interestingly, the morphy of jumping is just jumping not jump\n",
        "print(wn.morphy('jumping'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odip50_esgFY",
        "outputId": "1ec66384-d61f-4947-dc5a-557d9160b626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('swerve.v.01'), Synset('sheer.v.02'), Synset('absolute.s.02'), Synset('plain.s.04'), Synset('bluff.s.01'), Synset('diaphanous.s.01'), Synset('sheer.r.01'), Synset('sheer.r.02')]\n",
            "[Synset('cut.n.01'), Synset('cut.n.02'), Synset('cut.n.03'), Synset('cut.n.04'), Synset('cut.n.05'), Synset('cut.n.06'), Synset('stinger.n.02'), Synset('cut.n.08'), Synset('deletion.n.03'), Synset('cut.n.10'), Synset('cut.n.11'), Synset('snub.n.02'), Synset('baseball_swing.n.01'), Synset('cut.n.14'), Synset('cut.n.15'), Synset('cut.n.16'), Synset('cut.n.17'), Synset('cut.n.18'), Synset('cut.n.19'), Synset('cut.n.20'), Synset('cut.v.01'), Synset('reduce.v.01'), Synset('swerve.v.01'), Synset('cut.v.04'), Synset('cut.v.05'), Synset('cut.v.06'), Synset('cut.v.07'), Synset('cut.v.08'), Synset('write_out.v.02'), Synset('edit.v.03'), Synset('cut.v.11'), Synset('hack.v.02'), Synset('cut.v.13'), Synset('cut.v.14'), Synset('cut.v.15'), Synset('cut.v.16'), Synset('cut.v.17'), Synset('cut.v.18'), Synset('cut.v.19'), Synset('cut.v.20'), Synset('cut.v.21'), Synset('cut.v.22'), Synset('cut.v.23'), Synset('cut.v.24'), Synset('cut.v.25'), Synset('cut.v.26'), Synset('switch_off.v.01'), Synset('cut.v.28'), Synset('cut.v.29'), Synset('cut.v.30'), Synset('ignore.v.01'), Synset('cut.v.32'), Synset('cut.v.33'), Synset('cut.v.34'), Synset('cut.v.35'), Synset('cut.v.36'), Synset('abridge.v.01'), Synset('dilute.v.01'), Synset('cut.v.39'), Synset('cut.v.40'), Synset('geld.v.01'), Synset('cut.a.01'), Synset('cut.a.02'), Synset('cut.s.03'), Synset('trimmed.a.01'), Synset('mown.a.01'), Synset('cut.a.06'), Synset('cut.s.07'), Synset('cut.s.08'), Synset('cut.s.09')]\n",
            "Synset('swerve.v.01')\n",
            "Synset('cut.v.01')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "a = 'sheer'\n",
        "b = 'cut'\n",
        "print(wn.synsets(a))\n",
        "print(wn.synsets(b))\n",
        "\n",
        "# Synsets of interest\n",
        "a = wn.synset('swerve.v.01')\n",
        "b = wn.synset('cut.v.01')\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# Find the Wu-Palmer similarity\n",
        "wn.wup_similarity(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "# Use the Lesk Algorithm to find similarity\n",
        "sent_a = 'The car swerved to avoid the incoming vehicles'.split(' ')\n",
        "print(lesk(sent_a, 'swerve', 'v'))\n",
        "\n",
        "sent_b = 'I used scissors to cut the sheet of paper'.split(' ')\n",
        "print(lesk(sent_b, 'cut'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE_3xXlOvnA_",
        "outputId": "f690f71b-3611-43ae-ace5-9b3ab8291fbf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('swerve.v.01')\n",
            "Synset('edit.v.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wu-Palmer Similarity Score\n",
        "\n",
        "Based on the depth of their lowest common subsumer (LCS) node and their position in the WordNet hierarchy, two synsets are compared using the Wu-Palmer similarity score to determine how closely related they are.\n",
        "The score is between 0 (no similarity) and 1. (identical meanings). Since I picked two words that are relatively close, it gave me a score of `0.25`.\n",
        "\n",
        "## Lesk Algorithm\n",
        "\n",
        "The Lesk method determines the relationship between two synsets based on the overlap of words in their **definitions**.\n",
        "In my example, both approaches imply that \"cut\" and \"swerve\" are similar words but still have their own subtle differences in meaning. "
      ],
      "metadata": {
        "id": "N2pD5EyIxG2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentiWordNet\n",
        "\n",
        "SentiWordNet is a lexical resource that judges WordNet synsets to determine if they are positive, negative, or neutral sentiment by giving them polarity scores.\n",
        "Applications for natural language processing could make advantage of sentiment analysis such as analyzing social media posts or determining news article bias."
      ],
      "metadata": {
        "id": "S3nevnw0ysc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "w = swn.senti_synset('hideous.s.01')\n",
        "print(w)\n",
        "print(\"Positive score = \", w.pos_score())\n",
        "print(\"Negative score = \", w.neg_score())\n",
        "print(\"Objective score = \", w.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iPP_gWWzBY6",
        "outputId": "b72ae03f-8cf9-40f7-b802-065f8ddbcfa8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<hideous.s.01: PosScore=0.0 NegScore=0.875>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.875\n",
            "Objective score =  0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'i absolutely loved the way he flipped his hair'\n",
        "for s in sent.split(' '):\n",
        "    sys = list(swn.senti_synsets(s))\n",
        "    if len(sys) > 0:\n",
        "        print(sys[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baSVNPfvzQUT",
        "outputId": "700392bd-0f9f-4067-e782-5288777d228b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<absolutely.r.01: PosScore=0.5 NegScore=0.0>\n",
            "<love.v.01: PosScore=0.5 NegScore=0.0>\n",
            "<manner.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<helium.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<flip.v.01: PosScore=0.0 NegScore=0.0>\n",
            "<hair.n.01: PosScore=0.0 NegScore=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These scores pretty much directly reflected what I intended for SentiWordNet to read. Knowing these scores can defintely help (as I mentioned above) with the classification of social media posts and news article analysis. More generally, it helps the app know the sentiment of the text. This can be used to show certain trends or the status quo feeling towards a certain idea, if we scrape web data."
      ],
      "metadata": {
        "id": "MC4QA75A0od3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocations\n",
        "\n",
        "A collocation is a group of words that regularly occur together in a corpus of language, implying a close relationship or frequent usage in groups (such as a word phrase).\n",
        "The collocations module of NLTK uses statistical metrics like mutual information to locate and grade collocations in a corpus. "
      ],
      "metadata": {
        "id": "cZ8VDbsH1Db3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.book import *\n",
        "text4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZidSumPz-xP",
        "outputId": "41af31fe-a526-467c-c904-b27483bf664a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Inaugural Address Corpus>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text4.collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiAQGFE11eTc",
        "outputId": "3819192c-7efe-4dd6-a2d4-be141c0900ac"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure out Mutual information\n",
        "text = ' '.join(text4.tokens)\n",
        "text[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QRUC8sbS2NDm",
        "outputId": "0d9a6cc7-e3f7-4e6e-ca78-d87e43184b45"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fellow - Citizens of the Senate and of the House o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "vocab = len(set(text4))\n",
        "us = text.count('United States')/vocab\n",
        "print(\"p(United States) = \",us )\n",
        "u = text.count('United')/vocab\n",
        "print(\"p(United) = \", u)\n",
        "s = text.count('States')/vocab\n",
        "print('p(States) = ', s)\n",
        "pmi = math.log2(us / (u * s))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jMPjAN02giB",
        "outputId": "091c8293-2494-4182-9ea2-070df6d87f1f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(United States) =  0.015860349127182045\n",
            "p(United) =  0.0170573566084788\n",
            "p(States) =  0.03301745635910224\n",
            "pmi =  4.815657649820885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "vocab = len(set(text4))\n",
        "us = text.count('every citizen')/vocab\n",
        "print(\"p(every citizen) = \",us )\n",
        "u = text.count('fellow')/vocab\n",
        "print(\"p(every) = \", u)\n",
        "s = text.count('citizen')/vocab\n",
        "print('p(citizen) = ', s)\n",
        "pmi = math.log2(us / (u * s))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7IvQg3x2xyH",
        "outputId": "9815b7f0-2ff0-4645-9229-c597b2f209cf"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(every citizen) =  0.0016957605985037406\n",
            "p(every) =  0.013665835411471322\n",
            "p(citizen) =  0.032618453865336655\n",
            "pmi =  1.9275985490213754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that `every citizen`'s multual information score is much lower than `United States`, which shows that the latter is much more likely to be a collocation. This makes sense as there are very little cases where `United` appears without `States`. However, the use of `every` and `citizen` are relatively more common alone."
      ],
      "metadata": {
        "id": "h2lC_i_w3Ick"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}